{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Gist Memory Showcase\n",
    "\n",
    "Welcome to the `gist-memory` showcase! This notebook provides a hands-on introduction to the `gist-memory` library, a toolkit for developing and evaluating text compression strategies for Large Language Model (LLM) contexts.\n",
    "\n",
    "`gist-memory` helps you manage and compress text data (like dialogue history or large documents) to fit within the limited context windows of LLMs while retaining essential information.\n",
    "\n",
    "This notebook will walk you through:\n",
    "1.  **Setup**: Installing `gist-memory` and its dependencies in a Colab environment by downloading and installing from a ZIP archive of the repository.\n",
    "2.  **Core Functionality**: Defining a custom compression strategy, compressing text, and understanding key objects like `CompressedMemory` and `CompressionTrace`.\n",
    "3.  **Running Experiments**: Using the library's experiment framework to evaluate compression strategies for ingestion, history retrieval, and response generation tasks.\n",
    "4.  **Command Line Interface (CLI)**: A brief tour of the `gist-memory` CLI for quick operations without Python scripting.\n",
    "\n",
    "Let's get started!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Initial Setup: Install Dependencies\n",
    "\n",
    "First, we need to set up the environment. This involves downloading a ZIP archive of the `gist-memory` repository, extracting it, installing the package from the local files, and then downloading necessary dependencies and models.\n",
    "\n",
    "**Note**: If you are running this notebook locally and have already cloned the repository and set up a virtual environment, you might be able to skip some of these steps. However, these cells are designed to work in a fresh Google Colab environment."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1 Download and Unzip `gist-memory` Repository"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the main branch as a ZIP file\n",
    "!wget https://github.com/google/gist-memory/archive/refs/heads/main.zip -O gist-memory-main.zip\n",
    "\n",
    "# Unzip the archive\n",
    "!unzip -q gist-memory-main.zip\n",
    "# This creates a directory named gist-memory-main"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2 Install `gist-memory` Package from Local Directory"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the gist-memory package from the unzipped directory\n",
    "# This method installs the package into site-packages and makes its CLI available.\n",
    "!pip install ./gist-memory-main"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3 Install Dependencies from Extracted Repo\n",
    "\n",
    "Install the remaining dependencies listed in `requirements.txt` from the extracted `gist-memory-main` directory. This ensures all features, including those for development and testing shown in this notebook, are available."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r gist-memory-main/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.4 Download spaCy Model\n",
    "\n",
    "Download the English language model from spaCy, which is used for text processing tasks like sentence segmentation. SpaCy should have been installed as part of the `requirements.txt`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.5 Set up PYTHONPATH (Usually Not Needed with `pip install`)\n",
    "\n",
    "When a package is installed using `pip install <local_path>` or `pip install -e <local_path>`, it's typically placed in the Python environment's `site-packages` directory, which is already part of `sys.path`. Therefore, explicitly adding the directory to `PYTHONPATH` for the `gist_memory` library itself is usually not necessary for it to be importable.\n",
    "\n",
    "The following cell is commented out. You would only need something like this if you were working with a local copy that wasn't installed via `pip` and Python couldn't find the `gist_memory` modules."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('./gist-memory-main') # Only needed if not installed via pip and Python can't find the package"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.6 Download Pre-trained Models for `gist-memory`\n",
    "\n",
    "Download the default embedding model (for text vectorization) and a small chat model (for response generation experiments) using the `gist-memory` CLI. The CLI should be available after the `pip install ./gist-memory-main` step."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the default sentence transformer model for embeddings\n",
    "!gist-memory download-model --model-name all-MiniLM-L6-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download a small chat model for demonstration purposes\n",
    "!gist-memory download-chat-model --model-name distilgpt2"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.7 Configure Offline Usage (Optional)\n",
    "\n",
    "If you have downloaded all necessary models and want to ensure the notebook runs without attempting to access Hugging Face Hub, you can set these environment variables. For this showcase, we'll leave them commented out."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For offline use after all models are downloaded, uncomment the following lines:\n",
    "# import os\n",
    "# os.environ['HF_HUB_OFFLINE'] = '1'\n",
    "# os.environ['TRANSFORMERS_OFFLINE'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.8 Import Necessary Modules\n",
    "\n",
    "Import the Python modules from `gist_memory` and other libraries that we'll use throughout this notebook."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml # For pretty-printing experiment results\n",
    "from pathlib import Path\n",
    "\n",
    "# Core gist-memory components for experiments and strategy evaluation\n",
    "from gist_memory import (\n",
    "    ExperimentConfig,\n",
    "    HistoryExperimentConfig,\n",
    "    ResponseExperimentConfig,\n",
    "    run_experiment,\n",
    "    run_history_experiment,\n",
    "    run_response_experiment,\n",
    ")\n",
    "# Components for compression strategies and memory representation\n",
    "from gist_memory.compression import (\n",
    "    CompressionStrategy,\n",
    "    CompressedMemory,\n",
    "    CompressionTrace,\n",
    "    StrategyConfig,\n",
    "    TokenBudget,\n",
    "    TextBlock\n",
    ")\n",
    "from gist_memory.constants import ONBOARDING_DEMO_DIR # Example data directory\n",
    "from gist_memory.registry import register_compression_strategy # To register custom strategies\n",
    "from gist_memory.utils import read_text, setup_logging # Utility functions\n",
    "\n",
    "# Initialize logging for cleaner output\n",
    "setup_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Core Functionality: Compression Strategies\n",
    "\n",
    "At the heart of `gist-memory` is the `CompressionStrategy`. This is an extensible class that defines how text should be compressed. Let's define a simple custom strategy and see how it works."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1 Define a Custom Compression Strategy\n",
    "\n",
    "We'll create `TruncateStrategy`, a basic strategy that truncates text to a specified token budget. This demonstrates the fundamental structure of a `CompressionStrategy`:\n",
    "- It inherits from `CompressionStrategy`.\n",
    "- It has a unique `id`.\n",
    "- It implements the `compress` method, which takes a `TextBlock` and a `TokenBudget` and returns a `CompressedMemory` object and a `CompressionTrace` object."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TruncateStrategy(CompressionStrategy):\n",
    "    \"\"\"A simple strategy that truncates text to the token budget.\"\"\"\n",
    "    id = \"truncate\" # Unique identifier for this strategy\n",
    "\n",
    "    def __init__(self, config: StrategyConfig):\n",
    "        super().__init__(config)\n",
    "        # Initialization specific to this strategy can go here\n",
    "\n",
    "    def compress(self, text_block: TextBlock, budget: TokenBudget) -> tuple[CompressedMemory, CompressionTrace]:\n",
    "        \"\"\"Compresses text by truncating to the budget.\"\"\"\n",
    "        input_summary = self.summarize(text_block) # Get summary of input\n",
    "        \n",
    "        # Simple truncation based on tokens\n",
    "        tokens = self.tokenizer.encode(text_block.text)\n",
    "        truncated_tokens = tokens[:budget.value] # Slice tokens to meet budget\n",
    "        compressed_text = self.tokenizer.decode(truncated_tokens)\n",
    "        \n",
    "        # Create the CompressedMemory object\n",
    "        compressed_memory = CompressedMemory(\n",
    "            text=compressed_text,\n",
    "            interaction_id=text_block.interaction_id, # Preserve interaction context\n",
    "            source_block_ids=[text_block.id] # Track original source\n",
    "        )\n",
    "        output_summary = self.summarize(compressed_memory.to_text_block()) # Get summary of output\n",
    "        \n",
    "        # Create the CompressionTrace object for logging and analysis\n",
    "        trace = CompressionTrace(\n",
    "            strategy_name=self.id,\n",
    "            strategy_config=self.config.model_dump(), # Store strategy configuration\n",
    "            token_budget=budget,\n",
    "            input_summary=input_summary,\n",
    "            output_summary=output_summary,\n",
    "            details={\"truncation_details\": \"Tokens truncated from start\"} # Strategy-specific details\n",
    "        )\n",
    "        return compressed_memory, trace"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2 Register the Custom Strategy\n",
    "\n",
    "To make our `TruncateStrategy` available for use by its ID (e.g., in experiments), we register it with the library."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_compression_strategy(TruncateStrategy.id, TruncateStrategy)\n",
    "print(f\"Strategy '{TruncateStrategy.id}' registered successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3 Load Sample Data\n",
    "\n",
    "Let's load a sample text file from our extracted `gist-memory-main` directory to use for our compression demonstration. We'll use an excerpt about the moon landing."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the sample data file within the extracted repository directory.\n",
    "sample_data_file_path = Path('gist-memory-main/sample_data/moon_landing/01_landing.txt')\n",
    "\n",
    "# Load the content of the file\n",
    "if sample_data_file_path.exists():\n",
    "    sample_text = read_text(sample_data_file_path)\n",
    "    print(f\"Successfully loaded data from {sample_data_file_path}\\n\")\n",
    "    print(\"First 300 characters of the sample data:\\n\")\n",
    "    print(sample_text[:300])\n",
    "else:\n",
    "    print(f\"Error: Sample data file not found at {sample_data_file_path}.\")\n",
    "    print(\"Please ensure the path is correct relative to your notebook's working directory.\")\n",
    "    # Fallback text if file not found, to allow notebook to continue\n",
    "    sample_text = (\"This is a fallback text because the sample data file was not found. \"\n",
    "                   \"Please check the path. This text will be used for demonstration purposes instead.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4 Demonstrate Text Compression\n",
    "\n",
    "Now, we'll use our `TruncateStrategy` to compress the loaded sample text. We need to:\n",
    "1.  Create a `StrategyConfig`, which can specify things like the tokenizer to use.\n",
    "2.  Instantiate our `TruncateStrategy` with this config.\n",
    "3.  Create a `TextBlock` from our sample text.\n",
    "4.  Define a `TokenBudget`.\n",
    "5.  Call the `compress` method."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a StrategyConfig for TruncateStrategy.\n",
    "# We'll use 'all-MiniLM-L6-v2' as the tokenizer, which should be available from the download step.\n",
    "truncate_strategy_config = StrategyConfig(name=\"truncate_demo_config\", tokenizer_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# 2. Create an instance of the TruncateStrategy\n",
    "truncate_compressor = TruncateStrategy(config=truncate_strategy_config)\n",
    "\n",
    "# 3. Define a TextBlock for compression\n",
    "# TextBlock wraps the input text and associated metadata.\n",
    "text_to_compress_block = TextBlock(id=\"moon_landing_excerpt\", text=sample_text, interaction_id=\"demo_interaction_01\")\n",
    "\n",
    "# 4. Define a token budget (e.g., compress to a maximum of 75 tokens)\n",
    "compression_budget = TokenBudget(value=75, type=\"max_tokens\")\n",
    "\n",
    "# 5. Compress the text\n",
    "compressed_memory_output, compression_trace_output = truncate_compressor.compress(text_to_compress_block, compression_budget)\n",
    "\n",
    "print(f\"Compression complete using strategy '{truncate_compressor.id}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.5 Understanding `CompressedMemory` and `CompressionTrace`\n",
    "\n",
    "The `compress` method returned two important objects:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### `CompressedMemory`\n",
    "\n",
    "The `CompressedMemory` object encapsulates the result of the compression. Its most important attribute is `text`, which contains the compressed version of the input. It also stores metadata linking it to the original text and the interaction it belongs to."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Compressed Text Output ---:\\n\")\n",
    "print(compressed_memory_output.text)\n",
    "print(f\"\\nOriginal Text Length (tokens): {compression_trace_output.input_summary.num_tokens}\")\n",
    "print(f\"Compressed Text Length (tokens): {compression_trace_output.output_summary.num_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### `CompressionTrace`\n",
    "\n",
    "The `CompressionTrace` object logs detailed metadata about the compression process. This is invaluable for debugging, analysis, and understanding the behavior of a strategy. It includes:\n",
    "- The strategy name and its configuration.\n",
    "- The token budget applied.\n",
    "- Summaries of the input and output text (character counts, word counts, sentence counts, token counts).\n",
    "- Any custom details logged by the strategy."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Compression Trace Information ---:\\n\")\n",
    "print(f\"Strategy Name: {compression_trace_output.strategy_name}\")\n",
    "print(f\"Strategy Configuration: {compression_trace_output.strategy_config}\")\n",
    "print(f\"Token Budget: {compression_trace_output.token_budget.value} {compression_trace_output.token_budget.type}\")\n",
    "print(f\"Input Summary: Chars={compression_trace_output.input_summary.num_chars}, Words={compression_trace_output.input_summary.num_words}, Sents={compression_trace_output.input_summary.num_sents}, Tokens={compression_trace_output.input_summary.num_tokens}\")\n",
    "print(f\"Output Summary: Chars={compression_trace_output.output_summary.num_chars}, Words={compression_trace_output.output_summary.num_words}, Sents={compression_trace_output.output_summary.num_sents}, Tokens={compression_trace_output.output_summary.num_tokens}\")\n",
    "print(f\"Strategy-Specific Details: {compression_trace_output.details}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Running Experiments\n",
    "\n",
    "`gist-memory` provides a framework for systematically evaluating compression strategies. There are three main types of experiments, configured using specific data classes:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Experiment Configuration Objects:\n",
    "-   **`ExperimentConfig`**: Used for *ingestion experiments*. These evaluate how well a strategy compresses a single, potentially large, text document. Key metrics often include compression ratio, information preservation (if measurable via summarization or other techniques), and processing time.\n",
    "-   **`HistoryExperimentConfig`**: Used for *history retrieval experiments*. These assess a strategy's ability to compress dialogue history while retaining information that is useful for retrieving relevant past turns or facts. Metrics typically involve retrieval scores like Mean Reciprocal Rank (MRR) or Recall@k against ground-truth relevant items.\n",
    "-   **`ResponseExperimentConfig`**: Used for *response generation experiments*. These evaluate the quality of LLM-generated responses when the compressed dialogue history (produced by the strategy) is used as context. Evaluation can involve automated metrics (e.g., ROUGE, BLEU for summarization/translation tasks) or human evaluation."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1 Run Ingestion Experiment\n",
    "\n",
    "This experiment type evaluates how well a strategy compresses a single document. We'll use the `TruncateStrategy` and our moon landing text from the `gist-memory-main` directory."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the data for the ingestion experiment (reusing the sample data path from the extracted repo)\n",
    "ingestion_data_path = sample_data_file_path # Path('gist-memory-main/sample_data/moon_landing/01_landing.txt')\n",
    "\n",
    "if ingestion_data_path.exists():\n",
    "    # Create an ExperimentConfig for ingestion\n",
    "    # We use our registered 'truncate' strategy and its configuration.\n",
    "    ingestion_exp_config = ExperimentConfig(\n",
    "        id=\"ingestion_demo_experiment\",\n",
    "        experiment_type=\"ingestion\",\n",
    "        strategy_id=TruncateStrategy.id, # Using the ID of our registered strategy\n",
    "        strategy_config=truncate_strategy_config, # Using the config created earlier\n",
    "        dataset_path=str(ingestion_data_path), # Path to the text file\n",
    "        token_budgets=[50, 100], # Test with different token budgets\n",
    "        output_dir=\"./ingestion_experiment_output\" # Directory to save results\n",
    "    )\n",
    "\n",
    "    # Run the ingestion experiment\n",
    "    print(f\"Running ingestion experiment: {ingestion_exp_config.id}\")\n",
    "    ingestion_metrics_results = run_experiment(ingestion_exp_config)\n",
    "\n",
    "    # Print the metrics in a readable YAML format\n",
    "    print(\"\\n--- Ingestion Experiment Metrics ---:\\n\")\n",
    "    print(yaml.safe_dump(ingestion_metrics_results, indent=2, sort_keys=False))\n",
    "else:\n",
    "    print(f\"Error: Ingestion data file not found at {ingestion_data_path}. Skipping ingestion experiment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The output above typically includes metrics like compression ratio, number of tokens before and after compression for each budget, and processing time."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2 Run History Experiment\n",
    "\n",
    "This experiment evaluates a strategy's ability to compress dialogue history for effective retrieval. It uses a dataset of dialogues (from `gist-memory-main`) where specific past turns are marked as relevant to current turns.\n",
    "\n",
    "**Note**: The `truncate` strategy is very naive for history retrieval. More sophisticated strategies (like those using summarization or embedding similarity) would likely perform better here. This is for demonstration of the experiment mechanics."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the history dialogues data from the extracted repo\n",
    "history_dialogues_data_path = Path('gist-memory-main/tests/data/history_dialogues.yaml')\n",
    "\n",
    "if history_dialogues_data_path.exists():\n",
    "    # Create a HistoryExperimentConfig\n",
    "    # We'll use the 'truncate' strategy and its config again.\n",
    "    history_exp_config = HistoryExperimentConfig(\n",
    "        id=\"history_demo_experiment\",\n",
    "        experiment_type=\"history_retrieval\",\n",
    "        strategy_id=TruncateStrategy.id,\n",
    "        strategy_config=truncate_strategy_config,\n",
    "        dataset_path=str(history_dialogues_data_path),\n",
    "        # param_grid allows testing different strategy parameters or budgets\n",
    "        param_grid={\"token_budget\": [TokenBudget(value=100, type=\"max_tokens\"), TokenBudget(value=150, type=\"max_tokens\")]},\n",
    "        output_dir=\"./history_experiment_output\"\n",
    "    )\n",
    "\n",
    "    # Run the history experiment\n",
    "    print(f\"Running history experiment: {history_exp_config.id}\")\n",
    "    history_experiment_results = run_history_experiment(history_exp_config)\n",
    "\n",
    "    # Print the results\n",
    "    print(\"\\n--- History Experiment Results ---:\\n\")\n",
    "    print(yaml.safe_dump(history_experiment_results, indent=2, sort_keys=False))\n",
    "else:\n",
    "    print(f\"Error: History dialogues data not found at {history_dialogues_data_path}. Skipping history experiment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The results from a history experiment usually include retrieval metrics like MRR (Mean Reciprocal Rank) and Recall@k, indicating how well the compressed history helped in identifying relevant prior turns."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.3 Run Response Experiment\n",
    "\n",
    "A response experiment assesses how compressed memory affects the quality of responses from an LLM. It uses a dataset of dialogues (from `gist-memory-main`) where the task is to generate a response based on the history.\n",
    "\n",
    "**Note**: This experiment can take longer to run as it involves calls to an LLM (even a small local one like `distilgpt2`). The `truncate` strategy's impact on response quality might be detrimental if too much context is lost."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the response dialogues data from the extracted repo\n",
    "response_dialogues_data_path = Path('gist-memory-main/tests/data/response_dialogues.yaml')\n",
    "\n",
    "if response_dialogues_data_path.exists():\n",
    "    # Create a ResponseExperimentConfig\n",
    "    # We use 'distilgpt2' as the chat model, downloaded during setup.\n",
    "    response_exp_config = ResponseExperimentConfig(\n",
    "        id=\"response_demo_experiment\",\n",
    "        experiment_type=\"response_generation\",\n",
    "        strategy_id=TruncateStrategy.id, \n",
    "        strategy_config=truncate_strategy_config,\n",
    "        dataset_path=str(response_dialogues_data_path),\n",
    "        param_grid={\"token_budget\": [TokenBudget(value=100, type=\"max_tokens\")]},\n",
    "        chat_model_name=\"distilgpt2\", # LLM for generating responses\n",
    "        output_dir=\"./response_experiment_output\"\n",
    "    )\n",
    "\n",
    "    # Run the response experiment\n",
    "    print(f\"Running response experiment: {response_exp_config.id}\")\n",
    "    # This can take a few minutes depending on the dataset size and model\n",
    "    response_experiment_results = run_response_experiment(response_exp_config)\n",
    "\n",
    "    # Print the results\n",
    "    print(\"\\n--- Response Experiment Results ---:\\n\")\n",
    "    print(yaml.safe_dump(response_experiment_results, indent=2, sort_keys=False))\n",
    "else:\n",
    "    print(f\"Error: Response dialogues data not found at {response_dialogues_data_path}. Skipping response experiment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Response experiment results often include metrics like ROUGE or BLEU (if reference responses are available and the task is suitable), or qualitative examples of generated responses. The output here will show file paths where detailed per-instance results and generated texts are stored."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Command Line Interface (CLI) Showcase\n",
    "\n",
    "`gist-memory` also features a versatile Command Line Interface (CLI) for performing common operations without needing to write Python scripts. This is handy for quick tests, batch processing, model downloads, and direct interaction with compression strategies. The CLI became available after we installed `gist-memory` using `pip`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.1 Basic Help Command\n",
    "\n",
    "To view all available CLI commands and their general options, use the `--help` flag."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gist-memory --help"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.2 Compression Command (`compress`)\n",
    "\n",
    "The `compress` command lets you apply a compression strategy to text input directly or from a file. \n",
    "\n",
    "**Important Note**: The CLI uses strategies that are built into `gist-memory` or registered via its plugin system. The custom `TruncateStrategy` we defined and registered within this Python notebook session is *not* automatically available to the standalone CLI. For CLI examples, we'll use `truncate` if it's a built-in alias for a simple truncation strategy, or another standard built-in strategy like `gist` (which aims to create a gist of the text)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Compress a short text string using the 'truncate' strategy (if available as a built-in/plugin)\n",
    "# If 'truncate' isn't a known CLI strategy, this might default to another or error.\n",
    "# Let's assume a basic 'truncate' or 'passthrough' might be available for such a small budget.\n",
    "!gist-memory compress --strategy truncate --text \"This is a fairly long sentence that we want to compress using the command line interface to a small number of tokens.\" --budget 20\n",
    "\n",
    "# Example: Compress a text file using the 'gist' strategy\n",
    "# The path needs to point into the extracted 'gist-memory-main' directory.\n",
    "cli_sample_file = 'gist-memory-main/sample_data/moon_landing/01_landing.txt'\n",
    "if Path(cli_sample_file).exists():\n",
    "  !gist-memory compress --strategy gist --file {cli_sample_file} --budget 100\n",
    "else:\n",
    "  print(f\"CLI sample file not found: {cli_sample_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Common options for `gist-memory compress`:\n",
    "-   `--strategy <name>`: ID of the compression strategy (e.g., `gist`, `truncate`).\n",
    "-   `--text \"<string>\"`: The text string to compress.\n",
    "-   `--file <path>`: Path to a text file for compression.\n",
    "-   `--budget <int>`: The target token budget.\n",
    "-   `--tokenizer <name>`: (Optional) Specify a tokenizer if the strategy shouldn't use its default.\n",
    "-   `--output <path>`: (Optional) Path to save the compressed output (e.g., as JSON)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.3 Talk Command (`talk`)\n",
    "\n",
    "The `talk` command enables interactive chat with an LLM that uses a specified compression strategy to manage the conversation history. This is great for qualitatively evaluating how different strategies affect conversation flow and context retention.\n",
    "\n",
    "Running a fully interactive `talk` session is not feasible within a static notebook cell. Instead, we'll show how to get help for the command and a conceptual example of its use."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gist-memory talk --help"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Conceptual Usage of `talk`:**\n",
    "\n",
    "You would typically run these in your terminal:\n",
    "\n",
    "1.  **Talk with a strategy applied to the ongoing conversation history:**\n",
    "    ```bash\n",
    "    gist-memory talk --strategy gist --chat-model distilgpt2 --budget 150\n",
    "    ```\n",
    "    This starts an interactive session where `distilgpt2` is the LLM, and the `gist` strategy compresses the conversation history to about 150 tokens before each LLM call.\n",
    "\n",
    "2.  **Talk using a pre-compressed memory file:**\n",
    "    First, compress a document (using the extracted repo path):\n",
    "    ```bash\n",
    "    gist-memory compress --strategy gist --file ./gist-memory-main/sample_data/moon_landing/01_landing.txt --budget 200 --output moon_memory.json\n",
    "    ```\n",
    "    Then, start a conversation using this memory as initial context:\n",
    "    ```bash\n",
    "    gist-memory talk --memory moon_memory.json --chat-model distilgpt2 --message \"What were the main objectives?\"\n",
    "    ```\n",
    "\n",
    "For a non-interactive check within the notebook, you can try sending a single message. The behavior might vary:\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This attempts a non-interactive query using the 'truncate' strategy with a specified chat model.\n",
    "# The CLI might provide a single response or indicate it's for interactive use.\n",
    "!gist-memory talk --strategy truncate --chat-model distilgpt2 --message \"What is the capital of France?\" --budget 50"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.4 Other Useful CLI Commands\n",
    "\n",
    "The `gist-memory` CLI offers other utilities. Here are a few, with examples of how to get their help messages:\n",
    "\n",
    "-   `download-model`, `download-chat-model`: We used these in the setup to fetch models (e.g., `all-MiniLM-L6-v2`, `distilgpt2`).\n",
    "-   `stats`: Provides statistics about datasets or memory files.\n",
    "-   `validate`: Validates configuration files or memory formats against the library's schemas."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gist-memory stats --help\n",
    "!echo \"\\n---------------------------------------\\n\" # Visual separator\n",
    "!gist-memory validate --help"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Conclusion and Next Steps\n",
    "\n",
    "This notebook has provided a tour of `gist-memory`, covering:\n",
    "-   **Installation and Setup**: Getting your environment ready by downloading a ZIP of the repository, installing the package locally, and installing dependencies.\n",
    "-   **Core Concepts**: Defining custom `CompressionStrategy` classes, and understanding `CompressedMemory` and `CompressionTrace`.\n",
    "-   **Experiment Framework**: Running ingestion, history retrieval, and response generation experiments to evaluate strategies, using data from the extracted repository.\n",
    "-   **CLI Usage**: Interacting with `gist-memory` via the command line for compression and other utilities.\n",
    "\n",
    "We hope this showcase helps you get started with `gist-memory` for your own LLM context management tasks!\n",
    "\n",
    "### Further Resources:\n",
    "-   **GitHub Repository**: [https://github.com/google/gist-memory](https://github.com/google/gist-memory) (The `gist-memory-main` directory we created is an extraction of a ZIP from this.)\n",
    "-   **Documentation**: Check the `docs/` directory in the `gist-memory-main` folder for more in-depth information.\n",
    "-   **Examples**: Explore other examples in the `gist-memory-main/examples/` directory.\n",
    "\n",
    "Feel free to open issues on GitHub for questions, bug reports, or feature requests."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "colab": {
   "name": "gist_memory_showcase.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
