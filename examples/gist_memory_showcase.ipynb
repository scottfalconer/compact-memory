{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Gist Memory Showcase (scottfalconer/gist-memory fork)\n",
    "\n",
    "Welcome to the `gist-memory` showcase! This notebook provides a hands-on introduction to a specific fork (`scottfalconer/gist-memory`) of the `gist-memory` library. This version has had packaging fixes applied, simplifying its usage.\n",
    "\n",
    "`gist-memory` helps you manage and compress text data (like dialogue history or large documents) to fit within the limited context windows of LLMs while retaining essential information.\n",
    "\n",
    "This notebook will walk you through:\n",
    "1.  **Setup**: Cloning the `scottfalconer/gist-memory` fork, changing into its directory, and installing the package along with dependencies.\n",
    "2.  **Command Line Interface (CLI)**: A tour of the `gist-memory` CLI for quick operations.\n",
    "3.  **Advanced Usage: Python Interface**: Using `gist-memory` programmatically for custom strategies and detailed experiments.\n",
    "4.  **Conclusion**: Summary and next steps.\n",
    "\n",
    "**Important Note on Notebook Execution**: This notebook uses `%cd` to change the current directory. Subsequent cells will operate from within the cloned `gist-memory` repository root.\n",
    "\n",
    "Let's get started!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Initial Setup: Install Dependencies\n",
    "\n",
    "First, we need to set up the environment. This involves cloning the `scottfalconer/gist-memory` fork, changing our current directory into it, installing the package from local source, and then downloading necessary dependencies and models.\n",
    "\n",
    "**Note**: If you are running this notebook locally and have already cloned this specific fork and set up a virtual environment from within the repo root, you might be able to skip some of these steps. However, these cells are designed to work in a fresh Google Colab environment."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1 Clone `gist-memory` Repository (scottfalconer fork) and Change Directory"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the specified fork of the gist-memory repository\n",
    "!git clone https://github.com/scottfalconer/gist-memory.git\n",
    "\n",
    "# Change directory into the cloned repository\n",
    "# Subsequent commands will run from the root of the 'gist-memory' repository\n",
    "%cd gist-memory"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we are inside the `gist-memory` directory (from the `scottfalconer/gist-memory` fork), we can install the package and its dependencies using relative paths."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2 Install `gist-memory` Package from Local Source"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the gist-memory package from the local source (current directory)\n",
    "# The --no-build-isolation flag can be helpful if there are issues with \n",
    "# the build environment or specific package versions.\n",
    "!pip install . --no-build-isolation"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3 Install Dependencies from `requirements.txt`\n",
    "\n",
    "Install the remaining dependencies listed in `requirements.txt` from the current directory. This ensures all features, including those for development and testing shown in this notebook, are available."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.4 Download spaCy Model\n",
    "\n",
    "Download the English language model from spaCy, which is used for text processing tasks like sentence segmentation. SpaCy should have been installed as part of the `requirements.txt`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.5 Set up PYTHONPATH (Usually Not Needed with `pip install .`)\n",
    "\n",
    "When a package is installed using `pip install .` from its root directory, it's typically placed in the Python environment's `site-packages` directory and becomes accessible. Explicitly modifying `sys.path` is usually not necessary.\n",
    "\n",
    "The following cell is commented out."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# import os\n",
    "# sys.path.append(os.getcwd()) # os.getcwd() is now the repo root, if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.6 Download Pre-trained Models for `gist-memory`\n",
    "\n",
    "Download the default embedding model (for text vectorization) and a small chat model (for response generation experiments) using the `gist-memory` CLI. The CLI should be available after the `pip install .` step."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the default sentence transformer model for embeddings\n",
    "!gist-memory download-model --model-name all-MiniLM-L6-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download a small chat model for demonstration purposes\n",
    "!gist-memory download-chat-model --model-name tiny-gpt2"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.7 Configure Offline Usage (Optional)\n",
    "\n",
    "If you have downloaded all necessary models and want to ensure the notebook runs without attempting to access Hugging Face Hub, you can set these environment variables. For this showcase, we'll leave them commented out."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For offline use after all models are downloaded, uncomment the following lines:\n",
    "# import os\n",
    "# os.environ['HF_HUB_OFFLINE'] = '1'\n",
    "# os.environ['TRANSFORMERS_OFFLINE'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Command Line Interface (CLI) Showcase\n",
    "\n",
    "`gist-memory` also features a versatile Command Line Interface (CLI) for performing common operations without needing to write Python scripts. This is handy for quick tests, batch processing, model downloads, and direct interaction with compression strategies. The CLI became available after we installed `gist-memory` using `pip`.\n",
    "\n",
    "Since we are operating from within the `gist-memory` repository root, file paths for the CLI should also be relative to this root."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1 Basic Help Command\n",
    "\n",
    "To view all available CLI commands and their general options, use the `--help` flag."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gist-memory --help"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2 Compression Command (`compress`)\n",
    "\n",
    "The `compress` command lets you apply a compression strategy to various forms of input: a direct line of text, a single file, or an entire directory. The following subsections will demonstrate each of these use cases.\n",
    "\n",
    "**Important Note**: The CLI uses strategies that are built into `gist-memory` or registered via its plugin system. The custom `TruncateStrategy` we defined and registered within this Python notebook session is *not* automatically available to the standalone CLI. For CLI examples, we'll use `truncate` if it's a built-in alias for a simple truncation strategy, or another standard built-in strategy like `gist` (which aims to create a gist of the text)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Compress a short text string using the 'truncate' strategy (if available as a built-in/plugin)\n",
    "# This command demonstrates compressing a simple line of text. \n",
    "# We use the 'truncate' strategy to keep the beginning of the text, fitting it within a 20-token budget.\n",
    "!gist-memory compress --strategy truncate \"This is a fairly long sentence that we want to compress using the command line interface to a small number of tokens.\" --budget 20\n",
    "\n",
    "# Example: Compress a text file using the 'gist' strategy\n",
    "# This command demonstrates compressing an entire file. We use 'sample_data/moon_landing/full.txt'.\n",
    "# The 'gist' strategy is employed to summarize the content within a 100-token budget.\n",
    "# The `compress` command directly handles file paths.\n",
    "!gist-memory compress --strategy gist --file sample_data/moon_landing/full.txt --budget 100"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Example: Compress an entire directory using the 'gist' strategy\n",
    "# This command demonstrates compressing all supported files within a directory.\n",
    "# We use the 'sample_data/moon_landing' directory.\n",
    "# The 'gist' strategy will be applied to each file, and the overall output might be a concatenation or structured representation.\n",
    "# The `compress` command automatically detects that this is a directory and processes its contents.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Compress an entire directory using the 'gist' strategy\n",
    "# This command demonstrates compressing all supported files within a directory.\n",
    "# We use the 'sample_data/moon_landing' directory.\n",
    "# The 'gist' strategy will be applied to each file.\n",
    "# The `compress` command directly handles directory paths.\n",
    "!gist-memory compress --strategy gist sample_data/moon_landing --budget 200\n",
    "# You might want to add --output some_directory_output.json if you want to inspect results later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choosing a Strategy with `--strategy`\n",
    "\n",
    "The `--strategy` option is key to controlling how `gist-memory` compresses your text. Different strategies have different behaviors:\n",
    "\n",
    "*   **`gist`**: Aims to create a concise summary or gist of the text. (Already used in file/directory examples above).\n",
    "*   **`truncate`**: Simply cuts the text to fit the token budget, usually keeping the beginning. (Already used in the text line example above).\n",
    "*   **`passthrough`** (if available, or another simple built-in one): Might do minimal or no actual compression, useful for just token counting or as a baseline.\n",
    "\n",
    "You can switch between them easily. For example, to compress our `full.txt` using `truncate` instead of `gist`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of using a different strategy (truncate) on the full.txt file\n",
    "# The `compress` command directly handles file paths.\n",
    "!gist-memory compress --strategy truncate --file sample_data/moon_landing/full.txt --budget 100"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Common options for `gist-memory compress`:\n",
    "-   `--strategy <name>`: ID of the compression strategy (e.g., `gist`, `truncate`).\n",
    "-   `--text \"<string>\"`: The text string to compress.\n",
    "-   `--file <path>`: Path to a text file for compression (e.g., `sample_data/moon_landing/full.txt`).\n",
    "-   `--budget <int>`: The target token budget.\n",
    "-   `--tokenizer <name>`: (Optional) Specify a tokenizer if the strategy shouldn't use its default.\n",
    "-   `--output <path>`: (Optional) Path to save the compressed output (e.g., as JSON). The compressed text is typically printed to the standard output if `--output` is not specified. Using `--output` is recommended for saving results, especially for larger inputs or when integrating into scripts.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3 Talk Command (`talk`)\n",
    "\n",
    "The `talk` command enables interactive chat with an LLM that uses a specified compression strategy to manage the conversation history. This is great for qualitatively evaluating how different strategies affect conversation flow and context retention.\n",
    "\n",
    "Running a fully interactive `talk` session is not feasible within a static notebook cell. Instead, we'll show how to get help for the command and a conceptual example of its use."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gist-memory talk --help"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Conceptual Usage of `talk`:**\n",
    "\n",
    "You would typically run these in your terminal (from the repo root):\n",
    "\n",
    "1.  **Talk with a strategy applied to the ongoing conversation history:**\n",
    "    ```bash\n",
    "    gist-memory talk --strategy gist --chat-model tiny-gpt2 --budget 150\n",
    "    ```\n",
    "    This starts an interactive session where `tiny-gpt2` is the LLM, and the `gist` strategy compresses the conversation history to about 150 tokens before each LLM call.\n",
    "\n",
    "2.  **Talk using a pre-compressed memory file:**\n",
    "    First, compress a document (using path relative to repo root):\n",
    "    ```bash\n",
    "    gist-memory compress --strategy gist --file ./sample_data/moon_landing/full.txt --budget 200 --output moon_memory.json\n",
    "    ```\n",
    "    Then, start a conversation using this memory as initial context:\n",
    "    ```bash\n",
    "    gist-memory talk --memory moon_memory.json --chat-model tiny-gpt2 --message \"What were the main objectives?\"\n",
    "    ```\n",
    "\n",
    "For a non-interactive check within the notebook, you can try sending a single message. The behavior might vary:\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This attempts a non-interactive query using the 'truncate' strategy with a specified chat model.\n",
    "# The CLI might provide a single response or indicate it's for interactive use.\n",
    "!gist-memory talk --strategy truncate --chat-model tiny-gpt2 --message \"What is the capital of France?\" --budget 50"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4 Other Useful CLI Commands\n",
    "\n",
    "The `gist-memory` CLI offers other utilities. Here are a few, with examples of how to get their help messages:\n",
    "\n",
    "-   `download-model`, `download-chat-model`: We used these in the setup to fetch models (e.g., `all-MiniLM-L6-v2`, `tiny-gpt2`).\n",
    "-   `stats`: Provides statistics about datasets or memory files.\n",
    "-   `validate`: Validates configuration files or memory formats against the library's schemas."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gist-memory stats --help\n",
    "!echo \"\\n---------------------------------------\\n\" # Visual separator\n",
    "!gist-memory validate --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Advanced Usage: Python Interface\n",
    "\n",
    "After exploring the CLI, this section delves into using `gist-memory` programmatically with Python for more advanced customization and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1 Importing Modules for Python Usage\n",
    "\n",
    "While the Command Line Interface (CLI) is excellent for quick tests and applying standard strategies, you'll want to use the Python interface for more advanced tasks such as defining custom compression logic, integrating `gist-memory` into your own Python applications, or conducting detailed programmatic evaluations.\n",
    "\n",
    "To use `gist-memory` with Python for these purposes (as shown in the following sections), we first need to import the necessary modules. With the packaging fixes in the `scottfalconer/gist-memory` fork, imports should now use the standard package paths. `TokenBudget` has been removed due to import errors and usages changed to `int`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml # For pretty-printing experiment results\n",
    "from pathlib import Path\n",
    "\n",
    "# Core gist-memory components for experiments and strategy evaluation\n",
    "from gist_memory import (\n",
    "    ExperimentConfig,\n",
    "    HistoryExperimentConfig,\n",
    "    ResponseExperimentConfig,\n",
    "    run_experiment,\n",
    "    run_history_experiment,\n",
    "    run_response_experiment,\n",
    "    StrategyConfig # Now directly available or re-exported\n",
    ")\n",
    "\n",
    "# Components from submodules\n",
    "from gist_memory.compression import (\n",
    "    CompressionStrategy,\n",
    "    CompressedMemory,\n",
    "    CompressionTrace,\n",
    "    TextBlock\n",
    "    # TokenBudget removed due to ImportError\n",
    ")\n",
    "\n",
    "from gist_memory.constants import ONBOARDING_DEMO_DIR \n",
    "from gist_memory.registry import register_compression_strategy \n",
    "from gist_memory.utils import read_text, setup_logging \n",
    "\n",
    "# Initialize logging for cleaner output\n",
    "setup_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2 Defining and Using Custom Compression Strategies in Python\n",
    "\n",
    "While the CLI is useful for applying pre-built strategies, the Python interface offers the power to define entirely new compression logic or precisely configure existing ones. At the heart of this is the `CompressionStrategy` class. This section demonstrates how to create and use your own custom strategy, giving you full control over the compression process."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.2.1 Define a Custom Compression Strategy\n",
    "\n",
    "We'll create `TruncateStrategy`, a basic strategy that truncates text to a specified token budget. This demonstrates the fundamental structure of a `CompressionStrategy`:\n",
    "- It inherits from `CompressionStrategy`.\n",
    "- It has a unique `id`.\n",
    "- It implements the `compress` method, which takes a `TextBlock` and an integer token budget, and returns a `CompressedMemory` object and a `CompressionTrace` object."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TruncateStrategy(CompressionStrategy):\n",
    "    \"\"\"A simple strategy that truncates text to the token budget.\"\"\"\n",
    "    id = \"truncate\" # Unique identifier for this strategy\n",
    "\n",
    "    def __init__(self, config: StrategyConfig):\n",
    "        super().__init__(config)\n",
    "\n",
    "    def compress(self, text_block: TextBlock, budget: int) -> tuple[CompressedMemory, CompressionTrace]: # budget is now int\n",
    "        \"\"\"Compresses text by truncating to the budget.\"\"\"\n",
    "        input_summary = self.summarize(text_block) # Get summary of input\n",
    "        \n",
    "        # Simple truncation based on tokens\n",
    "        tokens = self.tokenizer.encode(text_block.text)\n",
    "        # budget is already an int, no need for budget.value\n",
    "        truncated_tokens = tokens[:budget] # Slice tokens to meet budget \n",
    "        compressed_text = self.tokenizer.decode(truncated_tokens)\n",
    "        \n",
    "        # Create the CompressedMemory object\n",
    "        compressed_memory = CompressedMemory(\n",
    "            text=compressed_text,\n",
    "            interaction_id=text_block.interaction_id, # Preserve interaction context\n",
    "            source_block_ids=[text_block.id] # Track original source\n",
    "        )\n",
    "        output_summary = self.summarize(compressed_memory.to_text_block()) # Get summary of output\n",
    "        \n",
    "        # Create the CompressionTrace object for logging and analysis\n",
    "        # Assuming self.config is a Pydantic model (StrategyConfig)\n",
    "        strategy_config_dump = self.config.model_dump() if hasattr(self.config, 'model_dump') else self.config\n",
    "        trace = CompressionTrace(\n",
    "            strategy_name=self.id,\n",
    "            strategy_config=strategy_config_dump, \n",
    "            token_budget=budget, # Pass the integer budget directly\n",
    "            input_summary=input_summary,\n",
    "            output_summary=output_summary,\n",
    "            details={\"truncation_details\": \"Tokens truncated from start\"} # Strategy-specific details\n",
    "        )\n",
    "        return compressed_memory, trace"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.2.2 Register the Custom Strategy\n",
    "\n",
    "To make our `TruncateStrategy` available for use by its ID (e.g., in experiments), we register it with the library."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_compression_strategy(TruncateStrategy.id, TruncateStrategy)\n",
    "print(f\"Strategy '{TruncateStrategy.id}' registered successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.2.3 Load Sample Data\n",
    "\n",
    "Let's load a sample text file. Since we've changed directory into `gist-memory`, paths are now relative to the repository root. We'll use an excerpt about the moon landing."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the sample data file (relative to repo root).\n",
    "sample_data_file_path = Path('sample_data/moon_landing/01_landing.txt')\n",
    "\n",
    "# Load the content of the file\n",
    "if sample_data_file_path.exists():\n",
    "    sample_text = read_text(sample_data_file_path)\n",
    "    print(f\"Successfully loaded data from {sample_data_file_path}\\n\")\n",
    "    print(\"First 300 characters of the sample data:\\n\")\n",
    "    print(sample_text[:300])\n",
    "else:\n",
    "    print(f\"Error: Sample data file not found at {sample_data_file_path}.\")\n",
    "    print(f\"Current directory: {Path.cwd()}\")\n",
    "    # Fallback text if file not found, to allow notebook to continue\n",
    "    sample_text = (\"This is a fallback text because the sample data file was not found. \"\n",
    "                   \"Please check the path. This text will be used for demonstration purposes instead.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.2.4 Demonstrate Text Compression\n",
    "\n",
    "Now, we'll use our `TruncateStrategy` to compress the loaded sample text. We need to:\n",
    "1.  Create a `StrategyConfig` instance.\n",
    "2.  Instantiate our `TruncateStrategy` with this config.\n",
    "3.  Create a `TextBlock` from our sample text.\n",
    "4.  Define an integer token budget.\n",
    "5.  Call the `compress` method."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a StrategyConfig for TruncateStrategy.\n",
    "truncate_strategy_config_obj = StrategyConfig(name=\"truncate_demo_config\", tokenizer_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# 2. Create an instance of the TruncateStrategy\n",
    "truncate_compressor = TruncateStrategy(config=truncate_strategy_config_obj)\n",
    "\n",
    "# 3. Define a TextBlock for compression\n",
    "# TextBlock wraps the input text and associated metadata.\n",
    "text_to_compress_block = TextBlock(id=\"moon_landing_excerpt\", text=sample_text, interaction_id=\"demo_interaction_01\")\n",
    "\n",
    "# 4. Define an integer token budget (e.g., compress to a maximum of 75 tokens)\n",
    "compression_budget_int = 75 \n",
    "\n",
    "# 5. Compress the text\n",
    "compressed_memory_output, compression_trace_output = truncate_compressor.compress(text_to_compress_block, compression_budget_int)\n",
    "\n",
    "print(f\"Compression complete using strategy '{truncate_compressor.id}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.2.5 Understanding `CompressedMemory` and `CompressionTrace`\n",
    "\n",
    "The `compress` method returned two important objects:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### `CompressedMemory`\n",
    "\n",
    "The `CompressedMemory` object encapsulates the result of the compression. Its most important attribute is `text`, which contains the compressed version of the input. It also stores metadata linking it to the original text and the interaction it belongs to."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Compressed Text Output ---:\\n\")\n",
    "print(compressed_memory_output.text)\n",
    "print(f\"\\nOriginal Text Length (tokens): {compression_trace_output.input_summary.num_tokens}\")\n",
    "print(f\"Compressed Text Length (tokens): {compression_trace_output.output_summary.num_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### `CompressionTrace`\n",
    "\n",
    "The `CompressionTrace` object logs detailed metadata about the compression process. This is invaluable for debugging, analysis, and understanding the behavior of a strategy. It includes:\n",
    "- The strategy name and its configuration.\n",
    "- The token budget applied.\n",
    "- Summaries of the input and output text (character counts, word counts, sentence counts, token counts).\n",
    "- Any custom details logged by the strategy."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Compression Trace Information ---:\\n\")\n",
    "print(f\"Strategy Name: {compression_trace_output.strategy_name}\")\n",
    "print(f\"Strategy Configuration: {compression_trace_output.strategy_config}\")\n",
    "# Assuming CompressionTrace.token_budget can now store an int or was adapted\n",
    "print(f\"Token Budget: {compression_trace_output.token_budget} tokens\") \n",
    "print(f\"Input Summary: Chars={compression_trace_output.input_summary.num_chars}, Words={compression_trace_output.input_summary.num_words}, Sents={compression_trace_output.input_summary.num_sents}, Tokens={compression_trace_output.input_summary.num_tokens}\")\n",
    "print(f\"Output Summary: Chars={compression_trace_output.output_summary.num_chars}, Words={compression_trace_output.output_summary.num_words}, Sents={compression_trace_output.output_summary.num_sents}, Tokens={compression_trace_output.output_summary.num_tokens}\")\n",
    "print(f\"Strategy-Specific Details: {compression_trace_output.details}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.3 Evaluating Strategies and Testing Results in Python\n",
    "\n",
    "Beyond applying strategies, it's crucial to evaluate their effectiveness. `gist-memory` provides a powerful experiment framework for systematically testing your custom strategies or different configurations of built-in ones. This allows you to gather metrics and compare performance for tasks like document ingestion, history retrieval, and response generation. This section explains how to set up and run these experiments."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Experiment Configuration Objects:\n",
    "-   **`ExperimentConfig`**: Used for *ingestion experiments*. These evaluate how well a strategy compresses a single, potentially large, text document. Key metrics often include compression ratio, information preservation (if measurable via summarization or other techniques), and processing time.\n",
    "-   **`HistoryExperimentConfig`**: Used for *history retrieval experiments*. These assess a strategy's ability to compress dialogue history while retaining information that is useful for retrieving relevant past turns or facts. Metrics typically involve retrieval scores like Mean Reciprocal Rank (MRR) or Recall@k against ground-truth relevant items.\n",
    "-   **`ResponseExperimentConfig`**: Used for *response generation experiments*. These evaluate the quality of LLM-generated responses when the compressed dialogue history (produced by the strategy) is used as context. Evaluation can involve automated metrics (e.g., ROUGE, BLEU for summarization/translation tasks) or human evaluation."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.3.1 Run Ingestion Experiment\n",
    "\n",
    "This experiment type evaluates how well a strategy compresses a single document. We'll use the `TruncateStrategy` and our moon landing text."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the data for the ingestion experiment (reusing the sample data path, now relative to repo root)\n",
    "ingestion_data_path = sample_data_file_path # Path('sample_data/moon_landing/01_landing.txt')\n",
    "\n",
    "if ingestion_data_path.exists():\n",
    "    # Create an ExperimentConfig for ingestion\n",
    "    ingestion_exp_config = ExperimentConfig(\n",
    "        id=\"ingestion_demo_experiment\",\n",
    "        experiment_type=\"ingestion\",\n",
    "        strategy_id=TruncateStrategy.id, \n",
    "        strategy_config=truncate_strategy_config_obj, \n",
    "        dataset_path=str(ingestion_data_path), \n",
    "        token_budgets=[50, 100], # Integer token budgets\n",
    "        output_dir=\"./ingestion_experiment_output\" \n",
    "    )\n",
    "\n",
    "    # Run the ingestion experiment\n",
    "    print(f\"Running ingestion experiment: {ingestion_exp_config.id}\")\n",
    "    ingestion_metrics_results = run_experiment(ingestion_exp_config)\n",
    "\n",
    "    # Print the metrics in a readable YAML format\n",
    "    print(\"\\n--- Ingestion Experiment Metrics ---:\\n\")\n",
    "    print(yaml.safe_dump(ingestion_metrics_results, indent=2, sort_keys=False))\n",
    "else:\n",
    "    print(f\"Error: Ingestion data file not found at {ingestion_data_path}. Current CWD: {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The output above typically includes metrics like compression ratio, number of tokens before and after compression for each budget, and processing time."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.3.2 Run History Experiment\n",
    "\n",
    "This experiment evaluates a strategy's ability to compress dialogue history for effective retrieval. It uses a dataset of dialogues where specific past turns are marked as relevant to current turns.\n",
    "\n",
    "**Note**: The `truncate` strategy is very naive for history retrieval. More sophisticated strategies (like those using summarization or embedding similarity) would likely perform better here. This is for demonstration of the experiment mechanics."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the history dialogues data (relative to repo root)\n",
    "history_dialogues_data_path = Path('tests/data/history_dialogues.yaml')\n",
    "\n",
    "if history_dialogues_data_path.exists():\n",
    "    # Create a HistoryExperimentConfig\n",
    "    history_exp_config = HistoryExperimentConfig(\n",
    "        id=\"history_demo_experiment\",\n",
    "        experiment_type=\"history_retrieval\",\n",
    "        strategy_id=TruncateStrategy.id,\n",
    "        strategy_config=truncate_strategy_config_obj, \n",
    "        dataset_path=str(history_dialogues_data_path),\n",
    "        # param_grid allows testing different strategy parameters or budgets\n",
    "        # Using integer for token_budget as TokenBudget class is not imported\n",
    "        param_grid={\"token_budget\": [100, 150]},\n",
    "        output_dir=\"./history_experiment_output\"\n",
    "    )\n",
    "\n",
    "    # Run the history experiment\n",
    "    print(f\"Running history experiment: {history_exp_config.id}\")\n",
    "    history_experiment_results = run_history_experiment(history_exp_config)\n",
    "\n",
    "    # Print the results\n",
    "    print(\"\\n--- History Experiment Results ---:\\n\")\n",
    "    print(yaml.safe_dump(history_experiment_results, indent=2, sort_keys=False))\n",
    "else:\n",
    "    print(f\"Error: History dialogues data not found at {history_dialogues_data_path}. Current CWD: {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The results from a history experiment usually include retrieval metrics like MRR (Mean Reciprocal Rank) and Recall@k, indicating how well the compressed history helped in identifying relevant prior turns."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.3.3 Run Response Experiment\n",
    "\n",
    "A response experiment assesses how compressed memory affects the quality of responses from an LLM. It uses a dataset of dialogues where the task is to generate a response based on the history.\n",
    "\n",
    "**Note**: This experiment can take longer to run as it involves calls to an LLM (even a small local one like `tiny-gpt2`). The `truncate` strategy's impact on response quality might be detrimental if too much context is lost."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the response dialogues data (relative to repo root)\n",
    "response_dialogues_data_path = Path('tests/data/response_dialogues.yaml')\n",
    "\n",
    "if response_dialogues_data_path.exists():\n",
    "    # Create a ResponseExperimentConfig\n",
    "    response_exp_config = ResponseExperimentConfig(\n",
    "        id=\"response_demo_experiment\",\n",
    "        experiment_type=\"response_generation\",\n",
    "        strategy_id=TruncateStrategy.id, \n",
    "        strategy_config=truncate_strategy_config_obj, \n",
    "        dataset_path=str(response_dialogues_data_path),\n",
    "        # Using integer for token_budget\n",
    "        param_grid={\"token_budget\": [100]},\n",
    "        chat_model_name=\"tiny-gpt2\", # LLM for generating responses\n",
    "        output_dir=\"./response_experiment_output\"\n",
    "    )\n",
    "\n",
    "    # Run the response experiment\n",
    "    print(f\"Running response experiment: {response_exp_config.id}\")\n",
    "    # This can take a few minutes depending on the dataset size and model\n",
    "    response_experiment_results = run_response_experiment(response_exp_config)\n",
    "\n",
    "    # Print the results\n",
    "    print(\"\\n--- Response Experiment Results ---:\\n\")\n",
    "    print(yaml.safe_dump(response_experiment_results, indent=2, sort_keys=False))\n",
    "else:\n",
    "    print(f\"Error: Response dialogues data not found at {response_dialogues_data_path}. Current CWD: {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Response experiment results often include metrics like ROUGE or BLEU (if reference responses are available and the task is suitable), or qualitative examples of generated responses. The output here will show file paths where detailed per-instance results and generated texts are stored."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Conclusion and Next Steps\n",
    "\n",
    "This notebook has provided a tour of the `scottfalconer/gist-memory` fork, covering:\n",
    "-   **Installation and Setup**: Cloning the specific fork, changing into its directory, and installing the package and dependencies locally.\n",
    "-   **Command Line Interface (CLI)**: A tour of the `gist-memory` CLI for quick operations.\n",
    "-   **Advanced Usage: Python Interface**: Using `gist-memory` programmatically for defining custom strategies, and the experiment framework.\n",
    "-   **Conclusion**: Summary and next steps.\n",
    "\n",
    "We hope this showcase helps you get started with this version of `gist-memory`!\n",
    "\n",
    "### Further Resources:\n",
    "-   **GitHub Repository (Fork Used)**: [https://github.com/scottfalconer/gist-memory](https://github.com/scottfalconer/gist-memory)\n",
    "-   **Original GitHub Repository**: [https://github.com/google/gist-memory](https://github.com/google/gist-memory) (This notebook uses a fork, but the original may also be of interest).\n",
    "-   **Documentation**: Check the `docs/` directory for more in-depth information.\n",
    "-   **Examples**: Explore other examples in the `examples/` directory.\n",
    "\n",
    "Feel free to open issues on the respective GitHub repositories for questions, bug reports, or feature requests."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "colab": {
   "name": "gist_memory_showcase.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
